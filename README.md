# GAN and CGAN latent vis
---
In this project, I examine the relationship between the dimensionality of the random latent vector used to generate images with a Conditional Generative Adversarial Network (CGAN) and the quality of the generated images, as measured by the Fr√©chet Inception Distance (FID) score. The results show that increasing the dimensionality of the latent vector leads to the generation of higher-quality images, but that there may be an optimal point beyond which further increases have little effect. My findings suggest that the FID score can be a useful measure of the quality of images generated by a CGAN and that the dimensionality of the latent vector plays a role in determining this quality. And this can be a metric to evaluate information contained in the dataset.

### Use following code to download Cloth & Model dataset.

``` {python}
!kaggle datasets download -d dqmonn/zalando-store-crawl -p datasets
!unzip datasets/zalando-store-crawl.zip -d datasets/
```

## Experiment 1 (Cloth & Model)

#### Data 

The Clothing Models dataset on Kaggle is a collection of images of clothing and models wearing the clothing. The dataset consists of 16.2k images and most of them are cloth with models. To fit the data for binary CGAN, I manually labeled data into two groups, only cloth, and cloth with models. Since the data set is highly imbalanced, I end up with 1870 images in each group.

#### Setup
Since the limited computation power and for visualization perpuse, I only trained three GAN model with input dim of 3, first GAN is unconditional GAN model and 3 dimensional input is pure random noise sampled form normal distribution. Second GAN model is a conditional GAN model, the first and second dimension of input is the same random noise sampled form normal distribution and the third dimension is binary label. The third GAN is also an conditional GAN but only the first dimension of input is random noise, the second and the third dimension is softmax label.
After trained these three GAN model, FID score between true images and generated images are then calculated for further analysis.

#### Result

UGAN CGAN2 CGAN1 True Images
UGAN
0 223.725 158.855 2283.79
CGAN2 223.725
0 468.738 2077.349
CGAN1 158.855
468.738 0 2489.150
TrueImages
2283.79 2077.349 2489.150 0
### DeBERTa scorer
|          | UGAN | UGAN_2 | CGAN_1 | True_Images |
|----------|---------|---------|---------|---------|
| UGAN     | 0       | 223.725 | 158.855  | 2283.79  |
| UGAN_2   | 223.725 | 0       | 468.738  | 2077.349 |
| CGAN_1   | 158.855 | 468.738 | 0        | 2489.150 |
|True_Images| 2283.79| 2077.349| 2489.150 | 0        |

## Experiment 2 (MNIST)

#### Data
The MNIST dataset is a collection of 70,000 28x28 pixel grayscale images of handwritten digits from 0 to 9, along with their corresponding labels. It is commonly used as a benchmark for evaluating machine learning models, particularly in the field of image classification. The MNIST dataset has also been used for tasks such as object recognition, image generation, and anomaly detection.


